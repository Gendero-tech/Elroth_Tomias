# Fichier : modules/emotionSync.py
import asyncio
import logging
import time
from typing import Dict, Any, Optional
from modules.module import Module
# NOTE: N√©cessite les styles vocaux pour la compatibilit√© avec TTS
from config import VOICE_STYLE_MAP 
from typing import Any # Import explicite de Any

logger = logging.getLogger('EmotionSync')

# --- CONFIGURATION AVANC√âE ---
# Dur√©e minimale (en secondes) pendant laquelle une √©motion (surtout du LLM) doit √™tre affich√©e
EMOTION_LOCK_DURATION = 1.5 
# ------------------------------

class EmotionSync:
    """
    Module utilitaire pour synchroniser l'√©motion dominante (d√©tect√©e ou d√©cid√©e)
    avec les modules de sortie : TTS (style de voix) et VTS/Animaze (expression faciale).
    G√®re la priorit√© et le cooldown pour des transitions fluides.
    """
    def __init__(self, signals: Any, tts_module: Any, avatar_module: Any):
        self.signals = signals
        self.tts = tts_module
        self.avatar_module = avatar_module
        
        # üöÄ AM√âLIORATION : Suivi de l'√©tat √©motionnel interne
        self.last_applied_emotion = "neutral"
        self.last_lock_time = 0.0
        
        # üöÄ AM√âLIORATION : Priorit√© des canaux (plus la valeur est √©lev√©e, plus la priorit√© est haute)
        self.channel_priority = {
            "llm": 10,       # √âmotion d√©cid√©e par le LLM (r√©ponse longue, narration)
            "detected": 5,   # √âmotion d√©tect√©e par STT/Vision (r√©flexe rapide)
            "default": 0     # √âmotion par d√©faut (idle, day)
        }
        
    def apply_emotion(self, emotion: str, source_channel: str = "detected"):
        """
        Applique l'√©motion aux syst√®mes de sortie en respectant la priorit√© et le cooldown.
        
        Args:
            emotion (str): L'√©motion √† appliquer (happy, sad, neutral, etc.).
            source_channel (str): Qui demande l'√©motion ('llm', 'detected', 'default').
        """
        emotion = emotion.lower()
        current_time = time.time()
        
        # 1. GESTION DU COOLDOWN (√âvite le spam VTS et l'√©crasement imm√©diat)
        time_since_lock = current_time - self.last_lock_time
        current_priority = self.channel_priority.get(source_channel, 0)
        
        if time_since_lock < EMOTION_LOCK_DURATION:
            # Pour des raisons de robustesse, on utilise 0 si la cl√© n'existe pas
            last_priority = self.channel_priority.get(self.last_applied_emotion, 0) 
            
            # Si la nouvelle √©motion a une priorit√© plus faible ou √©gale et que le temps n'est pas √©coul√©, on ignore.
            if current_priority <= last_priority:
                return 
        
        # 2. VTS/Animaze : Application de l'expression
        if self.avatar_module and hasattr(self.avatar_module, 'API') and hasattr(self.avatar_module.API, 'send_hotkey'):
             try:
                 # Envoie l'√©motion comme hotkey (VTS g√®re la mise en queue)
                 self.avatar_module.API.send_hotkey(emotion)
                 logger.debug(f"[Sync] Hotkey '{emotion}' envoy√©e √† l'avatar.")
             except Exception as e:
                 logger.error(f"[Sync] √âchec envoi hotkey VTS pour {emotion}: {e}")

        # 3. TTS : Synchronisation du style de voix
        voice_style = VOICE_STYLE_MAP.get(emotion, "default")
        if self.tts and hasattr(self.tts, 'API') and hasattr(self.tts.API, 'set_voice_style'):
            self.tts.API.set_voice_style(voice_style)
        
        # 4. Mise √† jour de l'√©tat interne (LOCK)
        self.last_applied_emotion = emotion
        self.last_lock_time = current_time
        
        # 5. Mise √† jour de l'√©tat global (Signals)
        self.signals.sio_queue.put(('last_emotion', emotion))
        logger.info(f"üíñ √âmotion appliqu√©e: {emotion} (Style vocal: {voice_style}, Source: {source_channel})")